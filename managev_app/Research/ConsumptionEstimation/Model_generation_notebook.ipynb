{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app.Investigation'; 'app' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-3d3680b2c9d6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mapp\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mapp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mapp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInvestigation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataInteractor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_fetcher\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDataFetcher\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mheatmap\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcorrplot\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'app.Investigation'; 'app' is not a package"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from app import app\n",
    "from app.Investigation.DataInteractor.data_fetcher import DataFetcher\n",
    "\n",
    "from heatmap import corrplot\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import integrate, stats\n",
    "from app import app\n",
    "\n",
    "# Regression models\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from app.Investigation.Route_segmentation.segmentation import gen_traces\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin'\n",
    "print(os.environ[\"PATH\"])\n",
    "\n",
    "import app.Investigation.OpenStreetMaps.associate_edges_to_operation as associate\n",
    "# The OSM Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read operation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"renault\"  # input()\n",
    "data_path = os.path.join(app.root_path) + \"/DataBackup/\" + name\n",
    "\n",
    "try:\n",
    "    loaded_data = pd.read_hdf(\n",
    "        data_path + \"_data.h5\", key=name + \"_updated_df_operation\"\n",
    "    )\n",
    "    features = pd.read_hdf(data_path + \"_data.h5\", key=name + \"_segments\")\n",
    "    features = segments[segments[\"mean_speed\"] > 0]\n",
    "    features = segments[segments[\"consumption_per_km\"] < 10]\n",
    "    features = segments[segments[\"consumption_per_km\"] > -10]\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Enter query\")\n",
    "    query = input() or \"SELECT * from operation limit 10\"\n",
    "    print(query)\n",
    "    data_fetcher = DataFetcher()\n",
    "    data_fetcher.upload_data_to_h5(name, query)\n",
    "    loaded_data = pd.read_hdf(\n",
    "        data_path + \"_data.h5\", key=name + \"_updated_df_operation\"\n",
    "    )\n",
    "    features = pd.read_hdf(data_path + \"_data.h5\", key=name + \"_segments\")\n",
    "\n",
    "loaded_data.vehicle_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of run metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(loaded_data['run'][loaded_data['vehicle_id']=='FSV110'].sum()/1000)\n",
    "print(loaded_data['run'][loaded_data['vehicle_id']=='GHW284'].sum()/1000)\n",
    "print(loaded_data['run'][loaded_data['vehicle_id']=='EGZ112'].sum()/1000, \"\\n\")\n",
    "\n",
    "\n",
    "print(loaded_data['odometer'][loaded_data['vehicle_id']=='FSV110'].iloc[-1] - loaded_data['odometer'][loaded_data['vehicle_id']=='FSV110'].iloc[0])\n",
    "print(loaded_data['odometer'][loaded_data['vehicle_id']=='GHW284'].iloc[-1] - loaded_data['odometer'][loaded_data['vehicle_id']=='GHW284'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_data = loaded_data[loaded_data.power_kw != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrigiendo usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_data.user_name[(loaded_data.user_name == '1er_alquiler') &\n",
    "                        (loaded_data.vehicle_id =='FSV110')] = 'Santiago_Echavarria_FSV110'\n",
    "\n",
    "loaded_data.user_name[(loaded_data.user_name == '1er_alquiler') &\n",
    "                        (loaded_data.vehicle_id =='GHW284')] = 'Juan_David_Mira_Alq2'\n",
    "\n",
    "loaded_data.user_name[(loaded_data.user_name == 'Juan_David_Mira') &\n",
    "                        (loaded_data.timestamp2 > 1.608e9)] = 'Juan_David_Mira_03'\n",
    "\n",
    "loaded_data.user_name[(loaded_data.user_name == 'Juan_David_Mira')] = 'Juan_David_Mira_01'\n",
    "\n",
    "loaded_data.user_name[(loaded_data.user_name == 'Juan_Mira')] = 'Juan_David_Mira_02'\n",
    "\n",
    "loaded_data.user_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrigiendo los pesos\n",
    "https://verne.elpais.com/verne/2016/04/19/articulo/1461079768_768006.html 61kg para mujeres y 67kg para hombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Para el ZOE y LEAF respectivamente \n",
    "loaded_data.mass[loaded_data.mass == 170] = 1502\n",
    "loaded_data.mass[loaded_data.mass == 1528] = 1562\n",
    "loaded_data.mass[loaded_data.mass == 1584] = 1564\n",
    "\n",
    "# Con acompañante mujer\n",
    "loaded_data['mass'] = np.where((\n",
    "    (loaded_data['user_name'] == 'Juan_David_Ochoa') |\n",
    "    (loaded_data['user_name'] == 'Ricardo_Mejia') |\n",
    "    (loaded_data['user_name'] == 'Jose_Alejandro_Montoya') |\n",
    "    (loaded_data['user_name'] == 'Ana_Cristina_G') | \n",
    "    (loaded_data['user_name'] == 'Esterban_Betancur') | \n",
    "    (loaded_data['user_name'] == 'Juan_Gregorio_Arrieta') |\n",
    "    (loaded_data['user_name'] == 'Sergio')),loaded_data.mass + 61 + 67, loaded_data.mass)\n",
    "\n",
    "# Con acompañante hombre\n",
    "loaded_data['mass'] = np.where((\n",
    "    (loaded_data['user_name'] == 'Juan_David_Mira_01')),\n",
    "    loaded_data.mass + 67 + 67, loaded_data.mass)\n",
    "\n",
    "# Los que manejaron solos (menos peso)\n",
    "loaded_data['mass'] = np.where((\n",
    "    (loaded_data['user_name'] == 'Santiago_Echavarria_FSV110') |\n",
    "    (loaded_data['user_name'] == 'Santiago_Echavarria_01') |\n",
    "    (loaded_data['user_name'] == 'Santiago_Echavarria') |\n",
    "    (loaded_data['user_name'] == 'Juan_David_Mira_Alq2') |\n",
    "    (loaded_data['user_name'] == 'Juan_David_Mira_02') |\n",
    "    (loaded_data['user_name'] == 'Jesus_Villa')),\n",
    "    loaded_data.mass + 62, loaded_data.mass)\n",
    "\n",
    "# Otros que manejaron solos \n",
    "loaded_data['mass'] = np.where((\n",
    "    (loaded_data['user_name'] == 'David_Rios') |\n",
    "    (loaded_data['user_name'] == 'Mauricio_Fernandez')),\n",
    "    loaded_data.mass + 67, loaded_data.mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 8])\n",
    "plt.scatter(x=loaded_data.timestamp2, y=loaded_data.user_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relacion entre pedal de aceleración y potencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FRV020 = loaded_data[\n",
    "    (loaded_data['vehicle_id'] == 'FRV020') &\n",
    "    ((loaded_data['power_kw'] < -1) | (loaded_data['power_kw'] > 1)) &\n",
    "    (loaded_data['throttle'] > 1) &\n",
    "    ((loaded_data['throttle'] < 29) | (loaded_data['throttle'] > 31))]\n",
    "FRV020_esteban = FRV020[FRV020['user_name'] == 'Esteban_Betancur']\n",
    "plt.figure()\n",
    "plt.scatter(x=FRV020['power_kw'], y=FRV020['throttle'])\n",
    "\n",
    "#Correlacion\n",
    "corr_coef, p_value = stats.pearsonr(FRV020['power_kw'].to_numpy(), FRV020['throttle'])\n",
    "print('Corr with power = ',corr_coef)\n",
    "print('P value = ',p_value)\n",
    "\n",
    "corr_coef_curr, p_value_curr = stats.pearsonr(FRV020['current'].to_numpy(), FRV020['throttle'])\n",
    "print('Corr with current = ',corr_coef_curr)\n",
    "print('P value = ',p_value_curr)\n",
    "\n",
    "corr_coef_acc, p_value_acc = stats.pearsonr(FRV020['mean_acc'].to_numpy(), FRV020['throttle'])\n",
    "print('Corr with acc = ',corr_coef_acc)\n",
    "print('P value = ',p_value_acc)\n",
    "print('len = ',len(FRV020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  \n",
    "features = features[features['kms'] <= 1.6]\n",
    "features = features[features['min_acc'] > -5]\n",
    "# features = features[(features['max_current'] < 250) ]\n",
    "\n",
    "# #features = features[(features['traffic_factor'] < 45) ]\n",
    "\n",
    "# # Cuando es con 1200 mts\n",
    "features = features[features['consumption'] < 1]\n",
    "\n",
    "# # Cuando es con 300mts\n",
    "features = features[(features['consumption'] > -0.5) & (features['consumption'] < 0.6)]\n",
    "\n",
    "# #features = features[(features['consumption_per_km'] < 0.8) ]\n",
    "\n",
    "# features = features[features['std_acc'] != 0]\n",
    "\n",
    "# #Solamente Zoe\n",
    "# features = features[(features['vehicle_id'] != 'FRV020') & (features['vehicle_id'] != 'FVQ731')]\n",
    "\n",
    "# features = features[(features['consumption_per_km'] > -4) | (features['consumption_per_km'] < 1) ].dropna()\n",
    "\n",
    "\n",
    "features.corr()['consumption'].sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_cols = [\n",
    "    'mean_acc', 'mean_temp',\n",
    "    'skew_acc', 'slope',\n",
    "    'mean_power','mean_current', 'std_power','std_current',\n",
    "    'osm_speed', 'mean_soc',\n",
    "    'consumption_per_km'\n",
    "]\n",
    "\n",
    "a = features.copy()\n",
    "a = a.rename(columns={'mean_speed':'osm_speed'})\n",
    "corr=a[heat_cols].corr()\n",
    "plt.figure(figsize=(8,8))\n",
    "corrplot(corr.sort_values(['slope']), size_scale=500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=features.consumption, y=features.slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[a['mean_power']!= 0]\n",
    "sns.pairplot(a.dropna().sort_values(['slope']), hue='slope_cat', palette='mako', vars=[\n",
    "#     'min_acc',\n",
    "    'slope',\n",
    "    'mean_power',\n",
    "#     'osm_speed',\n",
    "#     'consumption_per_km'\n",
    "], kind= 'scatter', height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rpm = loaded_data[loaded_data.rpm > 0]\n",
    "plt.scatter(x=rpm.rpm, y=rpm.speed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To implement - pace during route\n",
    "### TellsF the user if his current rate is lower or upper to the estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=features.copy() ##[(features['slope'] > -5) & (features['slope'] < 5)]\n",
    "# x['slope_cat'] = pd.cut(x[\"slope\"], np.arange(-5.1,5.2,3.4) )\n",
    "x = x[x['consumption_per_km'] > -0.2]\n",
    "\n",
    "x = x[x['user_name'] != 'Juan_David_Mira_01']\n",
    "x = x[x['user_name'] != 'Santiago_Echavarria_FSV110']\n",
    "\n",
    "x = x[x['user_name'] != 'Santiago_Echavarria']\n",
    "x = x[x['user_name'] != 'Santiago_Echavarria_01']  # Por ser muy atipico\n",
    "x = x[x['user_name'] != 'Juan_David_Mira_01']\n",
    "x = x[x['user_name'] != 'Juan_David_Mira_02']\n",
    "x = x[x['user_name'] != 'Juan_David_Mira_03']\n",
    "x = x[x['user_name'] != 'Juan_David_Mira_Alq2']\n",
    "\n",
    "x.loc[x['user_name'] == 'Ricardo_Mejia', 'user_name'] = 'Driver 0'\n",
    "x.loc[x['user_name'] == 'Jose_Alejandro_Montoya', 'user_name'] = 'Driver 1'\n",
    "x.loc[x['user_name'] == 'Juan_Gregorio_Arrieta', 'user_name'] = 'Driver 2'\n",
    "x.loc[x['user_name'] == 'Mauricio_Fernandez', 'user_name'] = 'Driver 3'\n",
    "x.loc[x['user_name'] == 'Sergio', 'user_name'] = 'Driver 4'\n",
    "x.loc[x['user_name'] == 'Jesus_Villa', 'user_name'] = 'Driver 5'\n",
    "x.loc[x['user_name'] == 'Juan_David_Ochoa', 'user_name'] = 'Driver 6'\n",
    "x.loc[x['user_name'] == 'David_Rios', 'user_name'] = 'Driver 7'\n",
    "x.loc[x['user_name'] == 'Ana_Cristina_G', 'user_name'] = 'Driver 8'\n",
    "x.loc[x['user_name'] == 'Esterban_Betancur', 'user_name'] = 'Driver 9'\n",
    "x.loc[x['user_name'] == 'usuarios_eafit_vehiculo_2', 'user_name'] = 'Driver 10'\n",
    "x.loc[x['user_name'] == 'sechava4', 'user_name'] = 'Driver 11'\n",
    "\n",
    "\n",
    "x = x[(x['user_name'] == 'Driver 10') | (x['user_name'] == 'Driver 11')]\n",
    "x.rename(columns={\"mean_power\": \"MBPO (kW)\",\"mean_speed\": \"Nominal speed (km/h)\",\n",
    "                                       'consumption_per_km': 'Consumption rate (kWh/km)','slope_cat':'Slope category'}, inplace=True)\n",
    "\n",
    "\n",
    "sns.catplot(x='Slope category', y='Consumption rate (kWh/km)', hue='user_name', data=x.sort_values(by=['user_name', 'slope' ]), kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Slope category', y=\"MBPO (kW)\", hue='user_name', data=x.sort_values(by=['user_name', 'slope' ]), kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Slope category', y='Nominal speed (km/h)', hue='user_name', data=x.sort_values(by=['user_name', 'slope' ]), kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from   scipy import stats\n",
    "\n",
    "x1=x[(x['slope'] > 2) ]\n",
    "x2=x[(x['slope'] > -2) & (x['slope'] <= 2)]\n",
    "\n",
    "stat, p, med, tbl = stats.median_test(x1['Consumption rate (kWh/km)'][(x1['user_name'] == 'Driver 2')],\n",
    "                                      x1['Consumption rate (kWh/km)'][(x1['user_name'] == 'Driver 6')])\n",
    "print('p = ' + str(p), '\\n')\n",
    "\n",
    "# Different slope group\n",
    "t2, p2 = stats.ttest_ind(x1['Consumption rate (kWh/km)'][(x1['user_name'] == 'Driver 2')] ,\n",
    "                         x2['Consumption rate (kWh/km)'][x2['user_name'] == 'Driver 6' ])\n",
    "print('For same user - different slope group')\n",
    "print('t = ' + str(t2))\n",
    "print('p = ' + str(p2), '\\n')\n",
    "\n",
    "# Same slope group > 1.7\n",
    "t2, p2 = stats.ttest_ind(x1['Consumption rate (kWh/km)'][(x1['user_name'] == 'Driver 2')] ,\n",
    "                         x1['Consumption rate (kWh/km)'][x1['user_name'] == 'Driver 6' ])\n",
    "print('For 2 different users - slope group > 2')\n",
    "print('t = ' + str(t2))\n",
    "print('p = ' + str(p2), '\\n')\n",
    "\n",
    "# Same slope group > 1.7\n",
    "t2, p2 = stats.ttest_ind(x1['Nominal speed (km/h)'][(x1['user_name'] == 'Driver 2')] ,\n",
    "                         x1['Nominal speed (km/h)'][x1['user_name'] == 'Driver 6' ])\n",
    "print('Nominal speed (km/h) For 2 different users - slope group > 2')\n",
    "print('t = ' + str(t2))\n",
    "print('p = ' + str(p2), '\\n')\n",
    "\n",
    "# Same slope group > 1.7\n",
    "t2, p2 = stats.ttest_ind(x1['MBPO (kW)'][(x1['user_name'] == 'Driver 2')] ,\n",
    "                         x1['MBPO (kW)'][x1['user_name'] == 'Driver 6' ])\n",
    "print('MBPO (kW) For 2 different users - slope group > 2')\n",
    "print('t = ' + str(t2))\n",
    "print('p = ' + str(p2), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate 25 km for measuring and rest for test (for the test cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features['cumdist1'] = features[(features['user_name'] == 'Santiago_Echavarria') ].kms.cumsum()  #features['cumdist'] \n",
    "features.loc[features['cumdist1'] > 70, 'user_name'] = 'Santiago_Echavarria_test'\n",
    "features.loc[features['cumdist1'] < 70, 'user_name'] = 'Santiago_Echavarria_measure'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se utiliza para train los datos de las pruebas contraladas de todos los usuariois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = features[(features['user_name'] != 'Santiago_Echavarria_test') &\n",
    "                 (features['user_name'] != 'Santiago_Echavarria_measure')]\n",
    "test = features.loc[features.index.difference(train.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.user_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slope groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slope_groups = train.groupby(by=[\"slope_cat\"])\n",
    "\n",
    "mean_features_by_slope = slope_groups[['mean_power', 'min_acc', 'consumption_per_km']].mean().reset_index()\n",
    "mean_features_by_slope.rename(columns={\n",
    "    \"mean_power\": \"mean_power_by_slope\", \n",
    "    \"min_acc\": \"mean_min_acc\",\n",
    "    'consumption_per_km': 'mean_consumption_per_km',\n",
    "    'slope':'slope_cat'\n",
    "}, inplace=True)\n",
    "\n",
    "mean_features_by_slope.to_csv('UserDrivingData/mean_features_by_slope.csv', index=False)\n",
    "\n",
    "\n",
    "#Se lee la que se saco con segmentos de 300m.\n",
    "mean_features_by_slope = pd.read_csv('UserDrivingData/mean_features_by_slope.csv')\n",
    "mean_features_by_slope['slope_cat'] = mean_features_by_slope['slope_cat'].astype('string')\n",
    "\n",
    "\n",
    "train_cons = pd.merge(left=train, right=mean_features_by_slope,\n",
    "                      left_on='slope_cat', right_on='slope_cat')\n",
    "\n",
    "train_cons['user_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User and slope groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_slope_groups = train.groupby(by=['slope_cat', 'user_name'])\n",
    "mean_features_by_user_and_slope = user_slope_groups[['mean_power', 'min_acc', 'consumption_per_km']].mean().reset_index()\n",
    "mean_features_by_user_and_slope.rename(columns={\n",
    "    \"mean_power\": \"mean_power_usr\",\n",
    "    \"min_acc\": \"mean_min_acc_usr\",\n",
    "    'consumption_per_km': 'mean_consumption_per_km_usr'\n",
    "}, inplace=True)\n",
    "\n",
    "mean_features_by_user_and_slope\n",
    "mean_features_by_user_and_slope.to_csv('UserDrivingData/mean_features_by_user_and_slope.csv', index=False)\n",
    "\n",
    "\n",
    "#Se lee la que se saco con segmentos de 300m.\n",
    "mean_features_by_user_and_slope = pd.read_csv('UserDrivingData/mean_features_by_user_and_slope.csv')\n",
    "mean_features_by_user_and_slope['slope_cat'] = mean_features_by_user_and_slope['slope_cat'].astype('string')\n",
    "\n",
    "train_cons = pd.merge(left=train_cons, right=mean_features_by_user_and_slope,\n",
    "                              left_on=['user_name', 'slope_cat'], right_on=['user_name', 'slope_cat'])\n",
    "\n",
    "# Esta tabla se sacó con segmentos de 300m\n",
    "mean_features_by_user_and_slope.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cols = ['max_power','slope']\n",
    "cols = ['mean_power_usr', 'mean_min_acc_usr', 'mean_speed', 'slope']\n",
    "model_ft = train_cons[cols]\n",
    "selected_ft = train_cons[['mean_power_usr', 'mean_min_acc_usr', 'mean_speed', 'slope', 'consumption_per_km']]\n",
    "\n",
    "print(len(selected_ft))\n",
    "\n",
    "selected_ft.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pickle import dump\n",
    "\n",
    "# For other sklearn models differente than linear regression\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_cons[selected_ft.columns])\n",
    "\n",
    "# For linear regression\n",
    "scaler_lm = MinMaxScaler()\n",
    "scaler_lm.fit(train_cons[model_ft.columns])\n",
    "\n",
    "train_scaled = pd.DataFrame(scaler.transform(train_cons[selected_ft.columns]), columns=selected_ft.columns)\n",
    "\n",
    "train_lm_scaled = pd.DataFrame(scaler_lm.transform(train_cons[model_ft.columns]), columns=model_ft.columns)\n",
    "train_lm_scaled['consumption_per_km'] = train_scaled['consumption_per_km']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'consumption_per_km ~ mean_power_usr + mean_min_acc_usr + mean_speed + slope -1' # 0.84\n",
    "#formula = 'consumption_per_km ~ slope + max_power -1' # 0.84\n",
    "\n",
    "\n",
    "lm_consumo = ols(formula = formula, data = train_cons[selected_ft.columns]).fit()\n",
    "print(lm_consumo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =[20,20])\n",
    "fig=sm.graphics.plot_partregress_grid(lm_consumo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test case :\n",
    "\n",
    "Aqui dividimos el set de validación en 2 partes: Santiago_Echavarria_measure y Santiago_Echavarria_test.\n",
    "Santiago_Echavarria_measure contiene 25 km de manejo y se utilizará para determinar los promedios de las conductas de usuario. El conjunto Santiago_Echavarria_test contiene los siguientes kilómetros y será el conjunto donde se aplicará el algoritmo basado en los promedios calculados de Santiago_Echavarria_measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_test = test[test['user_name']=='Santiago_Echavarria_test']\n",
    "test_measure = test[test['user_name']=='Santiago_Echavarria_measure']\n",
    "\n",
    "\n",
    "print(len(test_test))\n",
    "print(len(test_measure))\n",
    "\n",
    "\n",
    "slope_user_groups = test_measure.groupby(by=['slope_cat', 'user_name'])\n",
    "mean_features_by_user_and_slope = slope_user_groups[['mean_power', 'min_acc', 'consumption_per_km']].mean().reset_index()\n",
    "mean_features_by_user_and_slope.rename(columns={\n",
    "    \"mean_power\": \"mean_power_usr\",\n",
    "    \"min_acc\": \"mean_min_acc_usr\",\n",
    "    'consumption_per_km': 'mean_consumption_per_km_usr'\n",
    "}, inplace=True)\n",
    "\n",
    "mean_features_by_user_and_slope.user_name = 'Santiago_Echavarria_test'\n",
    "test_test = pd.merge(how='left', left=test_test, right=mean_features_by_user_and_slope,\n",
    "                              left_on=['user_name', 'slope_cat'], right_on=['user_name', 'slope_cat'])\n",
    "test_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_test = pd.merge(how='left', left=test_test, right=mean_features_by_slope,\n",
    "                     left_on=['slope_cat'], right_on=['slope_cat'])\n",
    "\n",
    "test_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test[['user_name', 'slope_cat']] = test_test[['user_name', 'slope_cat']].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_max_pot_per_user_and_slope['slope_cat'] = mean_max_pot_per_user_and_slope['slope_cat'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_consolidated = pd.merge(how='left', left=test_consolidated, right=mean_max_pot_per_user_and_slope,\n",
    "#                               left_on=['slope_cat', 'user_name'], right_on=['slope_cat', 'user_name'])\n",
    "# test_consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_test['mean_power_usr'] = test_test.apply(\n",
    "    lambda row: row['mean_power_by_slope'] if np.isnan(row['mean_power_usr']) else row['mean_power_usr'],\n",
    "    axis=1\n",
    ")\n",
    "test_test['mean_min_acc_usr'] = test_test.apply(\n",
    "    lambda row: row['mean_min_acc'] if np.isnan(row['mean_min_acc_usr']) else row['mean_min_acc_usr'],\n",
    "    axis=1\n",
    ")\n",
    "test_test['mean_consumption_per_km_usr'] = test_test.apply(\n",
    "    lambda row: row['mean_consumption_per_km'] if np.isnan(row['mean_consumption_per_km_usr']) else row['mean_consumption_per_km_usr'],\n",
    "    axis=1\n",
    ")\n",
    "test_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_test[cols].isna().sum() )\n",
    "\n",
    "test_scaled = pd.DataFrame(\n",
    "    scaler_lm.transform(\n",
    "        test_test[model_ft.columns]\n",
    "    ), columns=model_ft.columns)\n",
    "\n",
    "test_scaled[cols].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(\n",
    "    scaler.transform(\n",
    "        test_test[selected_ft.columns]\n",
    "    ), columns=selected_ft.columns\n",
    ")['consumption_per_km']\n",
    "\n",
    "predictions = lm_consumo.predict(test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test['consumption_per_km'] = test_test['consumption_per_km']\n",
    "predictions = lm_consumo.predict(test_test[cols])\n",
    "y_test_lm = test_test['consumption_per_km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(lm_consumo, open('UserDrivingData/linear_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_evaluation(y_test, predictions):\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    print('RMSE =',RMSE)\n",
    "    \n",
    "    rmspe = (np.sqrt(np.mean(np.square((y_test - predictions) / y_test)))) * 100\n",
    "    print('RMSPE =',rmspe)\n",
    "    \n",
    "    rme = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "    print('RME =',rme)\n",
    "\n",
    "\n",
    "    print('R2 =',r2_score(y_test, predictions))\n",
    "    print('max error=',max(abs(y_test - predictions)))\n",
    "    plt.figure()\n",
    "    plt.scatter(x=y_test, y=predictions)\n",
    "\n",
    "model_evaluation(y_test_lm, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = train_lm_scaled[cols].values\n",
    "y = train_lm_scaled['consumption_per_km'].values\n",
    "\n",
    "# Step 1\n",
    "# n_estimators=[,,,,,], max_depth=[,,,,,,]\n",
    "\n",
    "# Curva de aprendizaje\n",
    "# Variar train size \n",
    "\n",
    "# Curva de complejidad\n",
    "# x cada uno de los parámetros max_depth': 110, 'max_samples': 0.2, 'n_estimators': 45}\n",
    "randF_regr = RandomForestRegressor(n_estimators=149, max_depth=5,\n",
    "                                   random_state=0,max_features='auto' , criterion='mse', max_samples = 0.219)\n",
    "\n",
    "randF_regr.fit(X, y)\n",
    "y_pred = randF_regr.predict(test_scaled[cols].values)\n",
    "\n",
    "model_evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "print(\"Initialize Grid Search\")\n",
    "param_grid = { \n",
    "    'n_estimators': np.arange(5,70,5),\n",
    "    'max_depth' : np.arange(2,20,2),\n",
    "    'max_samples' : np.arange(0.1,0.9,0.1)\n",
    "}\n",
    "# create and fit a regression model, testing each parameter value\n",
    "\n",
    " \n",
    "\n",
    "model = RandomForestRegressor()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "n_estimators = np.arange(1,200,1)\n",
    "X_test = test_scaled[cols].values\n",
    "\n",
    "train_reg_results = []\n",
    "validation_reg_results = []\n",
    "train_reg_r2 = []\n",
    "validation_reg_r2 = []\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "val_r2 = []\n",
    "train_r2 = []\n",
    "\n",
    "for estimators in n_estimators:\n",
    "    reg = RandomForestRegressor(n_estimators = estimators, max_features='auto', max_depth=5, max_samples = 0.219,\n",
    "                                criterion = 'mse', random_state = 0)\n",
    "    reg.fit(X, y)\n",
    "    # Predicting the Traint set results\n",
    "    y_pred_train = reg.predict(X)\n",
    "    train_reg_results.append(np.sqrt(mean_squared_error(y, y_pred_train)))\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    validation_reg_results.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    train_reg_r2.append(mean_absolute_error(y, y_pred_train))\n",
    "\n",
    "    validation_reg_r2.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    #print('R2 =',r2_score(y_test, predictions))\n",
    "\n",
    "for i in range(len(train_reg_results)):\n",
    "    train_acc.append(train_reg_results[i])\n",
    "    val_acc.append(validation_reg_results[i])\n",
    "    train_r2.append(train_reg_r2[i])\n",
    "    val_r2.append(validation_reg_r2[i])\n",
    "\n",
    "\n",
    "plt.figure('Complexity curve')\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(n_estimators, train_acc, 'b', label = 'Training RMSE')\n",
    "plt.plot(n_estimators, val_acc, 'r', label = 'Validation RMSE')\n",
    "# plt.plot(n_estimators, train_r2, 'c', label = 'Training MAE')\n",
    "# plt.plot(n_estimators, val_r2, 'y', label = 'Validation MAE')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('number of estimators ', fontsize = 14)\n",
    "# plt.title('Complexity curves for random forest', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators[val_acc.index(min(val_acc))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "depths = np.arange(1,20,1)\n",
    "X_test = test_scaled[cols].values\n",
    "\n",
    "train_reg_results = []\n",
    "validation_reg_results = []\n",
    "train_reg_r2 = []\n",
    "validation_reg_r2 = []\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "val_r2 = []\n",
    "train_r2 = []\n",
    "\n",
    "for depth in depths:\n",
    "    reg = RandomForestRegressor(n_estimators = 48, max_features='auto', max_samples = 0.219,\n",
    "                                max_depth=depth, criterion = 'mse', random_state = 0, n_jobs=-1)\n",
    "    reg.fit(X, y)\n",
    "    # Predicting the Traint set results\n",
    "    y_pred_train = reg.predict(X)\n",
    "    train_reg_results.append(np.sqrt(mean_squared_error(y, y_pred_train)))\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    validation_reg_results.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    train_reg_r2.append(mean_absolute_error(y, y_pred_train))\n",
    "\n",
    "    validation_reg_r2.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    #print('R2 =',r2_score(y_test, predictions))\n",
    "\n",
    "for i in range(len(train_reg_results)):\n",
    "    train_acc.append(train_reg_results[i])\n",
    "    val_acc.append(validation_reg_results[i])\n",
    "    train_r2.append(train_reg_r2[i])\n",
    "    val_r2.append(validation_reg_r2[i])\n",
    "\n",
    "\n",
    "plt.figure('Complexity curve')\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(depths, train_acc, 'b', label = 'Training RMSE')\n",
    "plt.plot(depths, val_acc, 'r', label = 'Validation RMSE')\n",
    "# plt.plot(n_estimators, train_r2, 'c', label = 'Training MAE')\n",
    "# plt.plot(n_estimators, val_r2, 'y', label = 'Validation MAE')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('Maximun tree depth', fontsize = 14)\n",
    "# plt.title('Complexity curves for random forest', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths[val_acc.index(min(val_acc))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_samples = np.arange(0.1,0.9,0.01)\n",
    "X_test = test_scaled[cols].values\n",
    "\n",
    "train_reg_results = []\n",
    "validation_reg_results = []\n",
    "train_reg_r2 = []\n",
    "validation_reg_r2 = []\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "val_r2 = []\n",
    "train_r2 = []\n",
    "\n",
    "for max_sample in max_samples:\n",
    "    reg = RandomForestRegressor(n_estimators = 48, max_features='auto', max_samples = max_sample,\n",
    "                                max_depth=5, criterion = 'mse', random_state = 0, n_jobs=-1)\n",
    "    reg.fit(X, y)\n",
    "    # Predicting the Traint set results\n",
    "    y_pred_train = reg.predict(X)\n",
    "    train_reg_results.append(np.sqrt(mean_squared_error(y, y_pred_train)))\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    validation_reg_results.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    train_reg_r2.append(mean_absolute_error(y, y_pred_train))\n",
    "\n",
    "    validation_reg_r2.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    #print('R2 =',r2_score(y_test, predictions))\n",
    "\n",
    "for i in range(len(train_reg_results)):\n",
    "    train_acc.append(train_reg_results[i])\n",
    "    val_acc.append(validation_reg_results[i])\n",
    "    train_r2.append(train_reg_r2[i])\n",
    "    val_r2.append(validation_reg_r2[i])\n",
    "\n",
    "\n",
    "plt.figure('Complexity curve')\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(max_samples, train_acc, 'b', label = 'Training RMSE')\n",
    "plt.plot(max_samples, val_acc, 'r', label = 'Validation RMSE')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('Maximun samples', fontsize = 14)\n",
    "# plt.title('Complexity curves for random forest', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples[val_acc.index(min(val_acc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features=train_lm_scaled.columns[[0, 1, 2, 3]]\n",
    "importances = randF_regr.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(1)\n",
    "#plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(randF_regr, open('MachineLearningModels/randomForest_0_3_mean_consumption_maxerr_model.pkl', 'wb'))\n",
    "dump(scaler, open('MachineLearningModels/scaler.pkl', 'wb'))\n",
    "dump(scaler_lm, open('MachineLearningModels/scaler_lm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## \n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.8, learning_rate = 0.5,\n",
    "#                 max_depth = 10, n_estimators = 5)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.7, learning_rate = 0.3,\n",
    "                max_depth = 2, n_estimators = 41)\n",
    "\n",
    "\n",
    "xg_reg.fit(X, y)\n",
    "\n",
    "y_pred_xgb = xg_reg.predict(test_scaled[cols].values)\n",
    "model_evaluation(y_test, y_pred_xgb)\n",
    "\n",
    "# Save the model\n",
    "dump(xg_reg, open('MachineLearningModels/xg_reg_model.pickle.dat', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "print(\"Initialize Grid Search\")\n",
    "param_distributions = { \n",
    "    'colsample_bytree' : np.arange(0.1, 1, 0.1),\n",
    "    'learning_rate' : np.arange(0.1, 1, 0.1),\n",
    "    'n_estimators': [2,3,4,5],\n",
    "    'max_depth' : np.arange(10, 30, 2),\n",
    "    'objective' :['reg:squarederror']\n",
    "}\n",
    "# create and fit a regression model, testing each parameter value\n",
    "\n",
    " \n",
    "#     'n_estimators': np.arange(3,60,1),\n",
    "#     'max_depth' : np.arange(3,40,1),\n",
    "model = xgb.XGBRegressor()\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = np.arange(2,50,1)\n",
    "X_test = test_scaled[cols].values\n",
    "\n",
    "train_reg_results = []\n",
    "validation_reg_results = []\n",
    "train_reg_r2 = []\n",
    "validation_reg_r2 = []\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "val_r2 = []\n",
    "train_r2 = []\n",
    "\n",
    "for estimators in n_estimators:\n",
    "    \n",
    "    reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.75, learning_rate = 0.3,\n",
    "                max_depth = 2, n_estimators = estimators, n_jobs=-1)\n",
    "\n",
    "    \n",
    "    reg.fit(X, y)\n",
    "    # Predicting the Traint set results\n",
    "    y_pred_train = reg.predict(X)\n",
    "    train_reg_results.append(np.sqrt(mean_squared_error(y, y_pred_train)))\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    validation_reg_results.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    train_reg_r2.append(mean_absolute_error(y, y_pred_train))\n",
    "\n",
    "    validation_reg_r2.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    #print('R2 =',r2_score(y_test, predictions))\n",
    "\n",
    "for i in range(len(train_reg_results)):\n",
    "    train_acc.append(train_reg_results[i])\n",
    "    val_acc.append(validation_reg_results[i])\n",
    "    train_r2.append(train_reg_r2[i])\n",
    "    val_r2.append(validation_reg_r2[i])\n",
    "\n",
    "\n",
    "plt.figure('Complexity curve')\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(n_estimators, train_acc, 'b', label = 'Training RMSE')\n",
    "plt.plot(n_estimators, val_acc, 'r', label = 'Validation RMSE')\n",
    "# plt.plot(n_estimators, train_r2, 'c', label = 'Training MAE')\n",
    "# plt.plot(n_estimators, val_r2, 'y', label = 'Validation MAE')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('number of estimators ', fontsize = 14)\n",
    "#plt.title('Complexity curves for xgboost', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# El valor óptimo\n",
    "n_estimators[val_acc.index(min(val_acc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depths = np.arange(1,25,1)\n",
    "X_test = test_scaled[cols].values\n",
    "\n",
    "train_reg_results = []\n",
    "validation_reg_results = []\n",
    "train_reg_r2 = []\n",
    "validation_reg_r2 = []\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "val_r2 = []\n",
    "train_r2 = []\n",
    "\n",
    "for depth in depths:\n",
    "    \n",
    "    reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.75, learning_rate = 0.3,\n",
    "                max_depth = depth, n_estimators = 19, n_jobs=-1) \n",
    "    \n",
    "    reg.fit(X, y)\n",
    "    # Predicting the Traint set results\n",
    "    y_pred_train = reg.predict(X)\n",
    "    train_reg_results.append(np.sqrt(mean_squared_error(y, y_pred_train)))\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    validation_reg_results.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    train_reg_r2.append(mean_absolute_error(y, y_pred_train))\n",
    "\n",
    "    validation_reg_r2.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    #print('R2 =',r2_score(y_test, predictions))\n",
    "\n",
    "for i in range(len(train_reg_results)):\n",
    "    train_acc.append(train_reg_results[i])\n",
    "    val_acc.append(validation_reg_results[i])\n",
    "    train_r2.append(train_reg_r2[i])\n",
    "    val_r2.append(validation_reg_r2[i])\n",
    "\n",
    "\n",
    "plt.figure('Complexity curve')\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(depths, train_acc, 'b', label = 'Training RMSE')\n",
    "plt.plot(depths, val_acc, 'r', label = 'Validation RMSE')\n",
    "# plt.plot(n_estimators, train_r2, 'c', label = 'Training MAE')\n",
    "# plt.plot(n_estimators, val_r2, 'y', label = 'Validation MAE')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('Maximun tree depth', fontsize = 14)\n",
    "#plt.title('Complexity curves for random forest', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "depths[val_acc.index(min(val_acc))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of columns samples by tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsamples_bytree = np.arange(0.05,1,0.05)\n",
    "X_test = test_scaled[cols].values\n",
    "\n",
    "train_reg_results = []\n",
    "validation_reg_results = []\n",
    "train_reg_r2 = []\n",
    "validation_reg_r2 = []\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "val_r2 = []\n",
    "train_r2 = []\n",
    "\n",
    "for colsample_bytree in colsamples_bytree:\n",
    "    \n",
    "    reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = colsample_bytree, learning_rate = 0.3,\n",
    "                max_depth = 2, n_estimators = 19, n_jobs=-1) \n",
    "    \n",
    "    reg.fit(X, y)\n",
    "    # Predicting the Traint set results\n",
    "    y_pred_train = reg.predict(X)\n",
    "    train_reg_results.append(np.sqrt(mean_squared_error(y, y_pred_train)))\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    validation_reg_results.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    train_reg_r2.append(mean_absolute_error(y, y_pred_train))\n",
    "\n",
    "    validation_reg_r2.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    #print('R2 =',r2_score(y_test, predictions))\n",
    "\n",
    "for i in range(len(train_reg_results)):\n",
    "    train_acc.append(train_reg_results[i])\n",
    "    val_acc.append(validation_reg_results[i])\n",
    "    train_r2.append(train_reg_r2[i])\n",
    "    val_r2.append(validation_reg_r2[i])\n",
    "\n",
    "\n",
    "plt.figure('Complexity curve')\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(colsamples_bytree, train_acc, 'b', label = 'Training RMSE')\n",
    "plt.plot(colsamples_bytree, val_acc, 'r', label = 'Validation RMSE')\n",
    "# plt.plot(n_estimators, train_r2, 'c', label = 'Training MAE')\n",
    "# plt.plot(n_estimators, val_r2, 'y', label = 'Validation MAE')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('Column samples by tree', fontsize = 14)\n",
    "#plt.title('Complexity curves for random forest', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsamples_bytree[val_acc.index(min(val_acc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rates = np.arange(0.05,1,0.05)\n",
    "X_test = test_scaled[cols].values\n",
    "\n",
    "train_reg_results = []\n",
    "validation_reg_results = []\n",
    "train_reg_r2 = []\n",
    "validation_reg_r2 = []\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "val_r2 = []\n",
    "train_r2 = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    \n",
    "    reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.8, learning_rate = learning_rate,\n",
    "                max_depth = 2, n_estimators = 41, n_jobs=-1) \n",
    "    \n",
    "    reg.fit(X, y)\n",
    "    # Predicting the Traint set results\n",
    "    y_pred_train = reg.predict(X)\n",
    "    train_reg_results.append(np.sqrt(mean_squared_error(y, y_pred_train)))\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    validation_reg_results.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    train_reg_r2.append(mean_absolute_error(y, y_pred_train))\n",
    "\n",
    "    validation_reg_r2.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    #print('R2 =',r2_score(y_test, predictions))\n",
    "\n",
    "for i in range(len(train_reg_results)):\n",
    "    train_acc.append(train_reg_results[i])\n",
    "    val_acc.append(validation_reg_results[i])\n",
    "    train_r2.append(train_reg_r2[i])\n",
    "    val_r2.append(validation_reg_r2[i])\n",
    "\n",
    "\n",
    "plt.figure('Complexity curve')\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(learning_rates, train_acc, 'b', label = 'Training RMSE')\n",
    "plt.plot(learning_rates, val_acc, 'r', label = 'Validation RMSE')\n",
    "# plt.plot(n_estimators, train_r2, 'c', label = 'Training MAE')\n",
    "# plt.plot(n_estimators, val_r2, 'y', label = 'Validation MAE')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('Learning rates', fontsize = 14)\n",
    "#plt.title('Complexity curves for random forest', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates[val_acc.index(min(val_acc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = xgb.plot_tree(xg_reg,num_trees=17)\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(30, 35)\n",
    "# fig = plot.get_figure()\n",
    "# fig.savefig('test2png.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = xgb.plot_importance(xg_reg)\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 1,'learning_rate': 0.1,\n",
    "                'max_depth': 2, 'n_estimators': 24}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = train_lm_scaled[cols].values\n",
    "y = train_lm_scaled['consumption_per_km'].values\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "linear_regr = linear_model.LinearRegression(n_jobs=-1)\n",
    "\n",
    "linear_regr.fit(X, y)\n",
    "y_pred_linear = linear_regr.predict(test_scaled[cols].values)\n",
    "model_evaluation(y_test, y_pred_linear)\n",
    "dump(linear_regr, open('MachineLearningModels/linear_regr_sklearn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = train_lm_scaled[cols].values\n",
    "y = train_lm_scaled['consumption_per_km'].values\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "ann_regr = MLPRegressor( activation='relu', alpha=0, hidden_layer_sizes= (50), max_iter=705000,\n",
    "                        learning_rate='adaptive', warm_start=True, tol=1e-4, solver='lbfgs').fit(X, y)\n",
    "\n",
    "#regr = MLPRegressor(random_state=1, max_iter=500, solver='lbfgs', activation='relu', alpha=0.002, hidden_layer_sizes=(150,)).fit(X, y)\n",
    "y_ann=ann_regr.predict(test_scaled[cols].values)\n",
    "ann_regr.score(test_scaled[cols].values, y_test)\n",
    "\n",
    "model_evaluation(y_test, y_ann)\n",
    "dump(ann_regr, open('MachineLearningModels/ann_regr.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Initialize Grid Search\")\n",
    "param_grid = { \n",
    "    'solver':['lbfgs'],\n",
    "     #arning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    'hidden_layer_sizes': [(150,100), (150,)],\n",
    "    'activation': [\"logistic\"],\n",
    "    'max_iter':[10500],\n",
    "    }\n",
    "\n",
    "\n",
    "# create and fit a regression model, testing each parameter value\n",
    "\n",
    "\n",
    "model = MLPRegressor()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    " \n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    #if ylim is not None:\n",
    "        #axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    print('max train = ', np.mean(train_scores))\n",
    "    print('max test = ', np.mean(test_scores))\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "    print('Fitting time = ', np.mean(fit_times))\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    '''\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, np.sort(test_scores_mean), 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "    '''\n",
    "    return plt\n",
    "\n",
    "\n",
    "title = \"Learning Curves (Neural Network)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = MLPRegressor(random_state=1, activation='tanh', alpha=0,\n",
    "                         hidden_layer_sizes= (110 ), max_iter=70500, solver='lbfgs', learning_rate='invscaling')\n",
    "plot_learning_curve(estimator, title, X, y, # ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=-1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "title = \"Learning Curves (Random Forest)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = RandomForestRegressor(n_estimators = 53, max_features='auto', max_samples = 0.1,\n",
    "                                  max_depth=8, criterion = 'mse', random_state = 0, n_jobs=-1)\n",
    "plot_learning_curve(estimator, title, X, y, # ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show() \n",
    "\n",
    "plt.figure()\n",
    "title = \"Learning Curves (Ordinary least squares Linear Regression)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = linear_model.LinearRegression(n_jobs=-1)\n",
    "plot_learning_curve(estimator, title, X, y,  # ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "title = \"Learning Curves (XGBoost)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.8, learning_rate = 0.15,\n",
    "                             max_depth = 2, n_estimators = 18)\n",
    "\n",
    "plot_learning_curve(estimator, title, X, y, # ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}